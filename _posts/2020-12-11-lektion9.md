---
title: "Lektion IX"
date: 2020-12-11
header:
  image: /assets/images/BAIN9.png
  teaser: "/assets/images/BAIN9.png"
---

## Suchmaschinen und Discovery-Systeme: Teil II
Heute geht's weiter mit Suchmaschinen und Discovery-Systemen, in unserem Fall also mit VuFind. Wir sind schon fast am Ende des Kurses angelangt und jetzt brauchen wir alle noch ein bisschen Durchhaltevermögen, damit wir auch den Hilfe-das-Semester-ist-bald-fertig-Workload meistern. In diesem Sinne - los geht's mit dem, was wir in dieser Lektion gelernt haben! 

### Solr
Solr ist uns nach fast einem ganzen Semester Bibliotheks- und Archivinformatik wohl allen ein Begriff. Bisher wurde Solr aber nur am Rande erwähnt. Heute folgt eine Schnellbleiche dazu. 

[Solr](https://lucene.apache.org/solr/) ist eine open-source Suchmaschine, die in verschiedenen Anwendungsbereichen weit verbreitet ist und mittlerweile als Industriestandard gilt. Sie dient z.B. beim Discoverysystem VuFind als Suchmaschinen-Basis, wird aber auch von kommerziellen Produkten von Anbietern wie ExLibris verwendet. 

Solr selbst hat nicht wirklich eine Suchoberfläche. Die gibt es entweder integriert in die Adminoberfläche oder als Demo, die ist aber völlig ungestaltet und wirklich nur zu Testzwecken gedacht. Moderne Usability-Anforderungen werden hier wohl nicht erfüllt. 

Aber wie funktioniert Solr denn? 

[Solr](https://en.wikipedia.org/wiki/Apache_Solr) sucht mittels Volltextsuche. Damit die Dokumente in einer Datenbank per Volltext durchsuchbar sind, sind mehrere Schritte nötig. Zuerst werden alle Dokumente indexiert, also in ein maschinell lesbares Format konvertiert. Dann folgt die Suchanfrage des Nutzers, welche durch die lexikalische Suche von Solr nicht 1:1 übernommen wird, sondern z.B. auf Grundformen reduziert wird. Diese Suchanfrage wird in einem nächsten Schritt namens Mapping auf die in der Datenbank gelagerten Dokumente gemappt und so nach Treffern gesucht. Zum Schluss folgt dann noch das Ranking, das nach Relevanz passiert - dazu später noch etwas mehr. 

Es emppfiehlt sich bei Solr, vor dem Datenimport in einem Schema festzulegen, welche Datentypen und Felder überhaupt gewünscht sind. Es gibt zwar die Möglichkeit, ohne Schema (schemaless) zu importieren, da fehlt dann aber die direkte Kontrolle, wo die Daten dann landen. Wichtig ist dann auch, welche Datentypen diese Daten beinhalten (z.B. Tabellen, Text, Nummern, Geokoordinaten, etc.). Das wäre dann schon wichtig, dass die jeweiligen Daten ins entsprechende Feld ankommen, damit z.B. Geokoordinaten suchbar sind oder es sich nach Zeiträumen suchen lässt. Wenn man nur Text importiert, geht das natürlich nicht. Deshalb macht es wirklich Sinn, mit dem Schema zu arbeiten. 

### Suchindex vs. Datenbank
Bei einem Suchindex wie z.B. Solr oder einer Datenbank wie z.B. MySQL handelt es sich in beiden Fällen um Systeme, in dem Daten gespeichert und gezielt wieder rausgeholt werden. Aber die beiden Systeme haben unterschiedliche Schwerpunkte. 

So ist die Datenstruktur bei Suchindexen vergleichsweise eher flach. Jedes Objekt, das ich indexiere, ist genau ein Dokument mit verschiedenen Eigenschaften und Metadaten, aber es hat keine Beziehung zu anderen Objekten und steht alleine. Bei relationalen Datenbanken ist das - wie der Name schon sagt - anders. Hier gibt es Relationen und Beziehungen zwischen Objekten, was die Daten insgesamt viel strukturierter macht. 

Auch die Datenabfrage selbst läuft anders ab. Wie bereits erwähnt funktioniert Solr mit einer lexikalischen Suche. Der Suchbegriff selbst hat also Grammatik, während dem Suchprozess wird dieser aber auf seine Grundform reduziert und nach dieser Grundform wird dann auch gesucht. Bei Datenbanken werden via SQL-Abfragen bestimmte Datensätze abgefragt. Aber anders als bei der lexikalischen Suche vergleicht die Datenbank ihre Daten nur 1:1 mit dem Suchbegriff. 

Ein Suchindex hat weiter keine Kontrolle darüber, ob die darin enthaltenen Daten korrekt sind. Daten persistent zu sichern ist da nicht gut möglich, man speichert sie nur flüchtig. Bei einer Datenbank ist das anders. Die internen Datenbankregeln garantieren, dass der Datensatz auch im Falle eines Absturzes immer noch konsistent ist. In so einem Fall bleibt die Konsistenz der übrigen Datensätze erhalten, einfach ist derjenige, an dem man gerade gearbeitet hat, ist nach einem Absturz eventuell nicht mehr vorhanden.  

### Experimentieren mit VuFind
Nachdem wir letzte Woche VuFind bereits erfolgreich installiert und konfiguriert haben, können wir uns heute direkt mit den Übungen starten. 

#### Suchen mit VuFind vs. Solr
In dieser Übung soll die Suchoberfläche von VuFind direkt mit der Suche via Solr verglichen werden. 

Dazu brauchen wir die Beispieldaten, die wir letzte Woche bereits eingespielt haben. Bei VuFind wie auch bei Solr wurde nach dem Begriff `psychology`gesucht. Bei VuFind kam dieses Resultat zurück: 

![BILDVUFIND](https://raw.githubusercontent.com/leabaechli/bain/master/assets/images/VuFindSuche.png)

Bei Solr kamen die gleichen drei Resultate in der gleichen Reihenfolge raus. 

![BILDSOLR](https://raw.githubusercontent.com/leabaechli/bain/master/assets/images/SolrSuche.png)

Das ist wohl v.a. auf die doch eher kleine Anzahl an Datensätzen in unserer Testdatenbank zurückzuführen. Ich nehme an, dass bei grösseren Datenmengen das Suchresultat doch etwas anders aussehen würde. Denn ein Blick auf die Logdatei gibt Aufschluss darüber, wie genau gesucht wurde. 

Hier ein Blick auf die Solr-Abfrage: 

![BildSolrLog](https://raw.githubusercontent.com/leabaechli/bain/master/assets/images/SolrLog.png)

Diese ist sehr kurz und knackig, was v.a. darauf zurückzuführen ist, dass ich nur im Feld q mit dem Begriff `psychology`gesucht habe. Solr kann natürlich eigentlich viel mehr, aber alle diese Einstellungen habe ich nicht vorgenommen. 

Zum Vergleich dazu die Logdatei der Abfrage bei der VuFind-Suchoberfläche: 

![BildVuFindLog](https://raw.githubusercontent.com/leabaechli/bain/master/assets/images/VuFindLog.png)

Sieht ganz schön anders aus. Hier wird ersichtlich, wie viel da im Hintergrund bei einer VuFind-Anfrage läuft. 

Interessant sind dann auch diese paar Zeilen hier: 

![BildGewichtungLog](https://raw.githubusercontent.com/leabaechli/bain/master/assets/images/VuFindGewichtung.png)

Das ist nämlich die Gewichtung, wie die Titel angezeigt werden sollen, also die Relevanzsortierung. Da kann man dann feinjustieren, in welcher Reihenfolge die Treffermenge angezeigt wird. Da kann man natürlich sehr lange drüber diskutieren, was die besten Resultate gibt. Es gibt nicht wirklich ein richtig oder falsch, es kommt sehr darauf an, in welchem Fachgebiet man sich bewegt und wie wichtig die entsprechenden Angaben sind.  

#### Daten löschen
[folgt nocht]

![Datenlöschen](https://raw.githubusercontent.com/leabaechli/bain/master/assets/images/Datenloeschen.png)

![Datenlöschen Detail](https://raw.githubusercontent.com/leabaechli/bain/master/assets/images/DatenloeschenDetail.png)

#### Datenimport
[folgt nocht]

### Marktüberblick Discovery-Systeme
[folgt nocht]
