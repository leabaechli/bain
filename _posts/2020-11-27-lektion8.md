---
title: "Lektion VIII"
date: 2020-11-27
header:
  image: /assets/images/BAIN8.png
  teaser: "/assets/images/BAIN8.png"
---
## Metadaten modellieren und Schnittstellen nutzen: Teil III
Zum Abschluss des Metadaten-Teils dieser Vorlesung haben wir noch kurz über weitere Tools zur Metadatentransformation bzw. über Alternativen zu OpenRefine gesprochen. OpenRefine haben wir in den vergangenen zwei Lehreinheiten bereits kennengelernt. Ein grosser Vorteil dieses Programms liegt natürlich in der grafischen Benutzeroberfläche, in der die Ergebnisse unserer eingegebenen Transformationen direkt sichtbar werden. Bei der Datenanreicherung bzw. Reconciliation liegt auch der Schwerpunkt des Programms. Wir haben auch ein wenig mit der Skriptsprache GREL experimentiert, weitere, von uns nicht verwendete Skriptsprachen wären Jython oder Clojure. 

Es gibt neben OpenRefine jedoch noch andere Programme für die Modellierung von Metadaten. Eines davon, [MarcEdit](https://marcedit.reeset.net) haben wir im Kurs auch bereits kennen gelernt (mehr dazu: s. [Lektion VI](https://leabaechli.github.io/bain/lektion6/)). 

Ein weiteres Programm ist das auf Perl basierende [Catmandu](https://librecat.org). [noch ausführen]

Nicht zuletzt wurde auch [Metafacture](https://github.com/metafacture/metafacture-core), das auf Java basiert, angesprochen. [noch ausführen]

Es gibt im dem Sinn also keine "one size fits all"-Lösung für die Metadatenmodellierung. Es kommt immer auf den konkreten Anwendungsfall drauf an und nicht zuletzt auch darauf, welche Kenntnisse (z.B. der entsprechenden Programmiersprachen) bereits vorhanden sind. 


### JSON-APIs
Moderne APIs liefern oft Antworten im Format JSON (statt XML wie bei SRU oder OAI-PMH)
JSON lässt sich ebenso wie XML im Browser anschauen und gut maschinell verarbeiten

Beispiel für API: lobid-gnd
https://lobid.org/gnd/api

Suchergebnisse als JSON
Datensätze über ID direkt als JSON abrufen
Bulk-Downloads mit JSON lines
Was kann man damit bauen? Beispiel Autovervollständigung
Beispiel für Tool: scrAPIr
https://scrapir.org

Das Tool erlaubt Daten von bekannten Webseiten zu beziehen
genutzt werden dazu die APIs der Webseiten (in der Regel JSON)
es werden auch Vorlagen für Code (Javascript, Python) bereitgestellt
Beispiel Google Books: https://scrapir.org/data-management?api=Google_Books
 

### LIDO
Lightweight Information Describing Objects ist ein auf dem CIDOC Conceptual Reference Model (CRM) basierender XML-Standard zur Beschreibung von Kulturobjekten
CIDOC CRM definiert URI für Konzepte und Relationen
LIDO verwendet eine an CIDOC CRM orientierte Terminologie
LIDO folgt dem Linked Open Data-Paradigma
besonderes Merkmal von LIDO ist die ereignis-zentrierte Beschreibung von Objekten (Ereignisse als Entitäten)
durch die spezielle Struktur ist die verlustfreie Transformation in andere Formate jedoch schwierig

LIDO - Struktur
deskriptive Metadaten:
Identifikation (Titel/Name, Beschreibung, Maße, etc.)
Klassifikation (Art, Gattung, Form, etc.)
Ereignisse (Herstellung, Bearbeitung, Besitzwechsel, Restaurierung, etc.)
Relationen (Objekte, Personen, Orte, etc.)
administrative Metadaten:
Rechte (Objekt, Datensatz, Nutzung, Verbreitung, etc.)
Datensatz (Identifikation, Urheber, etc.)
Ressourcen (Digitalisat, Nachweis, etc.)
Unterscheidung zwischen display elements und index elements



## Suchmaschinen und Discovery-Systeme: Teil I
Weil sich unser Zeitplan etwas nach hinten verschoben hat, kamen wir heute nicht sehr weit mit den Discovery-Systemen. Wir haben uns alle gemeinsam die Software VuFind (Version 7.0.1) heruntergeladen und auf der virtuellen Maschine installiert. Die Installation war nicht ganz ohne ihre Tücken, hat aber dann schlussendlich geklappt. Dass wir die Installation Schritt für Schritt im Plenum durchgeführt haben, hat mir nochmals ein bisschen geholfen, die verschiedenen Funktionen der Linux-Shell noch ein bisschen besser nachvollziehen zu können. 

### VuFind
